{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 03 - Introduction to Natural Language Processing 01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FastText"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"imdb\")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_shuffle = dataset.shuffle(seed=42, load_from_cache_file=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fasttext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib.util import lower_and_remove_punctuation\n",
    "from datasets.dataset_dict import DatasetDict\n",
    "\n",
    "def format_for_fasttext(dataset : DatasetDict, file_name : str):\n",
    "    \"\"\"TODO\n",
    "    \"\"\"\n",
    "    with open(file_name, 'w', encoding=\"utf-8\") as f:\n",
    "        def write_to_file(element : dict) -> dict:\n",
    "            \"\"\"TODO\n",
    "            \"\"\"\n",
    "            f.write(\"__label__\" + str(element['label']) + \" \" +  lower_and_remove_punctuation(element)['text'] + '\\n')\n",
    "            return element\n",
    "\n",
    "        dataset.map(write_to_file, load_from_cache_file=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "format_for_fasttext(dataset_shuffle['train'], \"train.txt\")\n",
    "format_for_fasttext(dataset_shuffle['test'], \"test.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = fasttext.train_supervised(\"train.txt\")\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.test_label(\"test.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the train dataset into a train split (80%) et a validation split (20%)\n",
    "# both have the same proportion of 'label' values\n",
    "split_dataset = dataset_shuffle[\"train\"].train_test_split(train_size=0.8, seed=42, stratify_by_column='label')\n",
    "# Add the \"validation\" split to our `dataset_shuffle`\n",
    "dataset_shuffle[\"validation\"] = split_dataset.pop(\"test\")\n",
    "# Update the \"train\" set to our `dataset_shuffle`\n",
    "dataset_shuffle[\"train\"] = split_dataset.pop(\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "format_for_fasttext(dataset_shuffle['train'], \"train.txt\")\n",
    "format_for_fasttext(dataset_shuffle['validation'], \"validation.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_autotuned = fasttext.train_supervised(input='train.txt', autotuneValidationFile='validation.txt', verbose=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_autotuned.test_label(\"test.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"model dimension:\", model.get_dimension())\n",
    "print(\"model_autotuned dimension:\", model_autotuned.get_dimension())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"model input:\", model.get_input_matrix().shape)\n",
    "print(\"model_autotuned input:\", model_autotuned.get_input_matrix().shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"model output:\", model.get_output_matrix().shape)\n",
    "print(\"model_autotuned output:\", model_autotuned.get_output_matrix().shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "test_data = dataset['test'].map(lower_and_remove_punctuation, load_from_cache_file=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict all test dataset\n",
    "predicted_value = model.predict(test_data['text'])\n",
    "\n",
    "# cast string labels to int labels\n",
    "predicted_labels = list(map(lambda x : int(x[0][-1]), predicted_value[0]))\n",
    "\n",
    "# get all failures index\n",
    "failures_index_list = np.array(predicted_labels) != np.array(test_data['label'])\n",
    "\n",
    "# get all failures' text\n",
    "failures = np.array(test_data['text'])[failures_index_list]\n",
    "# get all failures' label\n",
    "failures_labels = np.array(test_data['label'])[failures_index_list]\n",
    "# get all failures' predicted value\n",
    "failures_predicted_labels = np.array(predicted_labels)[failures_index_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "false_negatif = failures_labels == 1\n",
    "print(\"false negatif:\\n\", failures[false_negatif][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "false_positif = failures_labels == 0\n",
    "print(\"false positif:\\n\", failures[false_positif][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "997ad1420b6b0c9e7b1b439f118c1a8b873a3bdb035e288815e3230309572cf3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
