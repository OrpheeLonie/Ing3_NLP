{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 02 - Introduction to NLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. How many splits does the dataset has ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import get_dataset_split_names\n",
    "\n",
    "get_dataset_split_names(\"imdb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is three splits: train, test and unsupervised."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. How big are these splits ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"imdb\")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.num_rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The train set has 25 000 rows, as the test set and the unsupervised has 50 000 rows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. What is the proportion of each class on the supervised splits ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.num_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.column_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.data['train']['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.data['test']['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The test and train sets are composed of half label 0 and half label 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lower_and_remove_punctuation(dict_elt):\n",
    "    '''\n",
    "    dict_elt : Lower and remove the punctuation in an element of a dictionary of the dataset, it requires ['text']\n",
    "    '''\n",
    "    dict_elt['text'] = dict_elt['text'].lower().translate(str.maketrans('', '', string.punctuation))\n",
    "    return dict_elt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_transform = dataset.map(lower_and_remove_punctuation)\n",
    "dataset_transform.data['train']['text'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have decided to use scikit-learn Pipeline with a CountVectorizer and MunltinomialNB classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "pipe = make_pipeline(CountVectorizer(), MultinomialNB())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('countvectorizer', CountVectorizer()),\n",
       "                ('multinomialnb', MultinomialNB())])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.fit(dataset_transform.data['train']['text'].to_numpy(), dataset_transform.data['train']['label'].to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_train = pipe.predict(dataset_transform.data['train']['text'].to_numpy()) == dataset_transform.data['train']['label'].to_numpy()\n",
    "prediction_test = pipe.predict(dataset_transform.data['test']['text'].to_numpy()) == dataset_transform.data['test']['label'].to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.91284"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_train.sum()/len(prediction_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8172"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "prediction_test.sum()/len(prediction_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TODO Question 4 : Why is accuracy a sufficient measure of evaluation here ?  \n",
    "    Because the given labels only has two options 0 for negative and 1 for positive ! well if you are that smart... just answer the question then XP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TODO BONUS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_index = [index for index,value in enumerate(prediction_test) if not value] # list of false element by prediction\n",
    "# len(list_index) / len(prediction_test) check if we have the good amount of false answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_index_0 = [index for index,value in enumerate(dataset_transform.data['test']['label'].to_numpy()) if value == 0 and index in list_index]\n",
    "list_index_1 = [index for index,value in enumerate(dataset_transform.data['test']['label'].to_numpy()) if value == 1 and index in list_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text:  blind date columbia pictures 1934 was a decent film but i have a few issues with this film first of all i dont fault the actors in this film at all but more or less i have a problem with the script also i understand that this film was made in the 1930s and people were looking to escape reality but the script made ann sotherns character look weak she kept going back and forth between suitors and i felt as though she should have stayed with paul kellys character in the end he truly did care about her and her family and would have done anything for her and he did by giving her up in the end to fickle neil hamilton who in my opinion was only out for a good time paul kellys character although a workaholic was a man of integrity and truly loved kitty ann sothern as opposed to neil hamilton while he did like her a lot i didnt see the depth of love that he had for her character the production values were great but the script could have used a little work\n",
      "label:  0\n"
     ]
    }
   ],
   "source": [
    "print(\"text: \", dataset_transform.data['test']['text'][list_index_0[0]])\n",
    "print(\"label: \", dataset_transform.data['test']['label'][list_index_0[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example the model has probably failed because the comment is not fully negative, it said that it's 'decent', have some 'problem'..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text:  i admire deepa mehta and this movie is a masterpiece id recommend to buy this movie on dvd because its a movie you might want to watch more often than just once and trust me youd still find little meaningful details after watching it several timesbr br the characters  except for the grandmother perhaps  are all very balanced no black and white even though you follow the story from the perspective of the two protagonists there is also empathy for the other charactersbr br i think the imdb rating for the movie is far too low  probably due to its politically controversial content\n",
      "label:  1\n"
     ]
    }
   ],
   "source": [
    "print(\"text: \", dataset_transform.data['test']['text'][list_index_1[0]])\n",
    "print(\"label: \", dataset_transform.data['test']['label'][list_index_1[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case the model classify wrong a text that was positive. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Stemming** ~~and Lemmatization~~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We choose stemming pretreatment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.tokenize import word_tokenize \n",
    "# We need to download a package for word tokenization\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def stemming_builder():\n",
    "    re_word = re.compile(r\"^\\w+$\")\n",
    "    stemmer = SnowballStemmer(\"english\")\n",
    "    def wesh(text):\n",
    "        stemmed = [stemmer.stem(word) for word in word_tokenize(text['text'].lower()) if re_word.match(word)]\n",
    "        text['text'] = \" \".join(stemmed)\n",
    "        return text\n",
    "    return wesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_stemming = dataset.map(stemming_builder())\n",
    "dataset_stemming.data['train']['text'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.fit(dataset_stemming.data['train']['text'].to_numpy(), dataset_stemming.data['train']['label'].to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_train = pipe.predict(dataset_stemming.data['train']['text'].to_numpy()) == dataset_stemming.data['train']['label'].to_numpy()\n",
    "prediction_test = pipe.predict(dataset_stemming.data['test']['text'].to_numpy()) == dataset_stemming.data['test']['label'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_train.sum()/len(prediction_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_test.sum()/len(prediction_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results be like :  \n",
    "![homer gif](homer.gif)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a990807983ab63add828142fed655c8c7d976d991d202393e435f5bc0896527f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
